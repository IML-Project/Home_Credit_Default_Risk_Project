{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents:\n",
    "* 1 [Preparation](#intro-bullet)\n",
    "* 2 [Logistic Regression](#first-bullet)\n",
    "* 3 [Random Forest](#second-bullet)\n",
    "* 4 [Naive Bayes](#third-bullet)\n",
    "* 5 [LigthGBM](#fourth-bullet)\n",
    "    * 5.1 [Plain LigthGBM](#fifth-bullet)\n",
    "    * 5.2 [LightGBM with LR](#sixth-bullet)\n",
    "    * 5.3 [LigthGBM with RF](#seventh-bullet)\n",
    "    * 5.4 [LigthGBM with NB](#eigth-bullet)\n",
    "* 6 [XGBM](#nineth-bullet)\n",
    "    * 6.1 [Plain XGBM](#tenth-bullet)\n",
    "    * 6.2 [XGBM with LR](#eleventh-bullet)\n",
    "    * 6.3 [XGBM with RF](#12-bullet)\n",
    "    * 6.4 [XGBM with NB](#13-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation <a class=\"anchor\" id=\"intro-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michał's path\n",
    "#train_data = pd.read_csv(\"/Users/michael/Documents/GitHub/Home_Credit_Default_Risk_Project/train.csv\")\n",
    "#test_data = pd.read_csv(\"/Users/michael/Documents/GitHub/Home_Credit_Default_Risk_Project/test.csv\")\n",
    "\n",
    "# Łukasz's path\n",
    "train_data = pd.read_csv(\"/train.csv\")\n",
    "test_data = pd.read_csv(\"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data.drop(columns='Unnamed: 0')\n",
    "train_data=train_data.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>24750.0</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256500.0</td>\n",
       "      <td>473760.0</td>\n",
       "      <td>51151.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>110331.0</td>\n",
       "      <td>13221.0</td>\n",
       "      <td>103500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>485640.0</td>\n",
       "      <td>31401.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>381515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>781920.0</td>\n",
       "      <td>25969.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61498</th>\n",
       "      <td>453002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>288873.0</td>\n",
       "      <td>13464.0</td>\n",
       "      <td>238500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61499</th>\n",
       "      <td>173166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>53329.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61500</th>\n",
       "      <td>207489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>1190340.0</td>\n",
       "      <td>63549.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61501</th>\n",
       "      <td>126929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>808650.0</td>\n",
       "      <td>26217.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61502</th>\n",
       "      <td>327244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>521280.0</td>\n",
       "      <td>35392.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61503 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0          161767       0                   1             0                0   \n",
       "1          157105       0                   0             1                1   \n",
       "2          268658       0                   0             0                1   \n",
       "3          376177       0                   0             0                0   \n",
       "4          381515       0                   0             0                1   \n",
       "...           ...     ...                 ...           ...              ...   \n",
       "61498      453002       0                   0             1                1   \n",
       "61499      173166       0                   0             0                1   \n",
       "61500      207489       0                   0             1                1   \n",
       "61501      126929       0                   0             1                1   \n",
       "61502      327244       0                   0             1                1   \n",
       "\n",
       "       CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0                 0          180000.0    495000.0      24750.0   \n",
       "1                 0          256500.0    473760.0      51151.5   \n",
       "2                 0          157500.0    110331.0      13221.0   \n",
       "3                 0          135000.0    485640.0      31401.0   \n",
       "4                 0           90000.0    781920.0      25969.5   \n",
       "...             ...               ...         ...          ...   \n",
       "61498             1          112500.0    288873.0      13464.0   \n",
       "61499             0          315000.0    675000.0      53329.5   \n",
       "61500             0          180000.0   1190340.0      63549.0   \n",
       "61501             0          144000.0    808650.0      26217.0   \n",
       "61502             0          157500.0    521280.0      35392.5   \n",
       "\n",
       "       AMT_GOODS_PRICE  ...  HOUSETYPE_MODE_terraced house  \\\n",
       "0             495000.0  ...                              0   \n",
       "1             450000.0  ...                              0   \n",
       "2             103500.0  ...                              0   \n",
       "3             450000.0  ...                              0   \n",
       "4             675000.0  ...                              0   \n",
       "...                ...  ...                            ...   \n",
       "61498         238500.0  ...                              0   \n",
       "61499         675000.0  ...                              0   \n",
       "61500        1125000.0  ...                              0   \n",
       "61501         675000.0  ...                              0   \n",
       "61502         450000.0  ...                              0   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0                             0                         0   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "...                         ...                       ...   \n",
       "61498                         0                         0   \n",
       "61499                         0                         0   \n",
       "61500                         0                         0   \n",
       "61501                         0                         0   \n",
       "61502                         0                         0   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                                  0                          0   \n",
       "1                                  0                          0   \n",
       "2                                  0                          0   \n",
       "3                                  0                          0   \n",
       "4                                  0                          0   \n",
       "...                              ...                        ...   \n",
       "61498                              0                          0   \n",
       "61499                              0                          0   \n",
       "61500                              0                          0   \n",
       "61501                              0                          0   \n",
       "61502                              0                          0   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                             0                                0   \n",
       "1                             1                                0   \n",
       "2                             0                                1   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "...                         ...                              ...   \n",
       "61498                         0                                0   \n",
       "61499                         1                                0   \n",
       "61500                         1                                0   \n",
       "61501                         0                                0   \n",
       "61502                         1                                0   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_No  \\\n",
       "0                              0                       1   \n",
       "1                              0                       1   \n",
       "2                              0                       1   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "...                          ...                     ...   \n",
       "61498                          0                       0   \n",
       "61499                          0                       1   \n",
       "61500                          0                       1   \n",
       "61501                          0                       0   \n",
       "61502                          0                       1   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_Yes  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "61498                        0  \n",
       "61499                        0  \n",
       "61500                        0  \n",
       "61501                        0  \n",
       "61502                        0  \n",
       "\n",
       "[61503 rows x 243 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "def LogRegModel(train, test):\n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET'])\n",
    "    test= test.drop(columns = ['TARGET'])\n",
    "    # Make the model with the specified regularization parameter\n",
    "    log_reg = LogisticRegression(C = 0.0001)\n",
    "    # Train on the training data\n",
    "    log_reg.fit(train, labels)\n",
    "    # Select only second column(TARGET)\n",
    "    log_reg_pred = log_reg.predict_proba(test)[:, 1]\n",
    "    tescik = log_reg.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik, average=\"micro\")\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, log_reg_pred))\n",
    "    print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "ROC 0.6308539127767936\n",
      "F1 score: 0.921207\n"
     ]
    }
   ],
   "source": [
    "LogRegModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def RanForModel(train,test):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=10,min_samples_split=20,\n",
    "                                min_samples_leaf=6,\n",
    "                                max_features='auto')\n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET'])\n",
    "    test= test.drop(columns = ['TARGET'])\n",
    "    \n",
    "    rf.fit(X = train, y = labels)\n",
    "    # Select only second column(TARGET)\n",
    "    ran_for_pred = rf.predict_proba(test)[:, 1]\n",
    "    \n",
    "    tescik = rf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik, average=\"micro\")\n",
    "    print('F1 score: %f' % f1)\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, ran_for_pred))\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.921207\n",
      "Train/Test split results:\n",
      "ROC 0.7331459444200834\n"
     ]
    }
   ],
   "source": [
    "RanForModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive Bayesn <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def NaiveBayModel(train,test):\n",
    "    \n",
    "    \n",
    "    clf = BernoulliNB()\n",
    "    \n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    \n",
    "    clf.fit(X = train, y = labels)\n",
    "    clf_pred = clf.predict_proba(test)[:, 1]\n",
    "    tescik = clf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik, average=\"micro\")\n",
    "    print('F1 score: %f' % f1)\n",
    "\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, clf_pred))\n",
    "    f1 = f1_score(test_labels, tescik, average=\"micro\")\n",
    "    print('F1 score: %f' % f1)\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.872819\n",
      "Train/Test split results:\n",
      "ROC 0.6301445318536083\n",
      "F1 score: 0.872819\n"
     ]
    }
   ],
   "source": [
    "NaiveBayModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LigthGBM <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Plain LightGBM <a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 LightGBM with LR <a class=\"anchor\" id=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "def PlainLightGBM(train,test):\n",
    "    \n",
    "    model = lgb.LGBMClassifier()\n",
    "    \n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "    n_scores = cross_val_score(model, train, labels, scoring='roc_auc_ovo_weighted', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    model.fit(X = train, y = labels)\n",
    "    model_pred = model.predict_proba(test)[:, 1]\n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik, average=\"micro\")\n",
    "     \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print('F1 score: %f' % f1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "ROC 0.7567481158987639\n",
      "F1 score: 0.921630\n"
     ]
    }
   ],
   "source": [
    "PlainLightGBM(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 LightGBM with RF <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 LightGBM with NB <a class=\"anchor\" id=\"eigth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBM <a class=\"anchor\" id=\"nineth-bullet\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Plain XGBM -- to long do not use <a class=\"anchor\" id=\"tenth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "def PlainXGBM(train,test):\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    model.fit(X = train, y = labels)\n",
    "    model_pred = model.predict_proba(test)[:, 1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlainXGBM(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 XGBM with LR<a class=\"anchor\" id=\"eleventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 XGBM with RF <a class=\"anchor\" id=\"12-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 XGBM with NB <a class=\"anchor\" id=\"13-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not completed -- do not use it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(param_grid, max_evals = 5):\n",
    "    \"\"\"Random search for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # Dataframe for results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                                  index = list(range(5)))\n",
    "    \n",
    "    # Keep searching until reach max evaluations\n",
    "    for i in range(5):\n",
    "        \n",
    "        # Choose random hyperparameters\n",
    "        hyperparameters = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n",
    "\n",
    "        # Evaluate randomly selected hyperparameters\n",
    "        eval_results = objective(hyperparameters, i)\n",
    "        \n",
    "        results.loc[i, :] = eval_results\n",
    "    \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newModel(train,test):\n",
    "    # Extract the test ids and train labels\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "\n",
    "    train = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test = test.drop(columns = ['SK_ID_CURR'])\n",
    "\n",
    "    print('Training shape: ', train.shape)\n",
    "    print('Testing shape: ', test.shape)\n",
    "    train_set = lgb.Dataset(train, label = train_labels)\n",
    "    random_results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                              index = list(range(5)))\n",
    "    random_search_params = random_results.loc[0, 'params']\n",
    "    \n",
    "    hyperparameters = dict(**random_results.loc[0, 'hyperparameters'])\n",
    "    del hyperparameters['n_estimators']\n",
    "\n",
    "    # Cross validation with n_folds and early stopping\n",
    "    cv_results = lgb.cv(hyperparameters, train_set,\n",
    "                    num_boost_round = 10000, early_stopping_rounds = 100, \n",
    "                    metrics = 'auc', nfold = N_FOLDS)\n",
    "    \n",
    "    print('The cross validation score on the full dataset = {:.5f} with std: {:.5f}.'.format(\n",
    "    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\n",
    "    print('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))\n",
    "    # Train the model with the optimal number of estimators from early stopping\n",
    "    model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\n",
    "    model.fit(train, train_labels)\n",
    "                        \n",
    "    # Predictions on the test data\n",
    "    preds = model.predict_proba(test)[:, 1]\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\n",
    "    submission.to_csv('submission_simple_features_random.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not complete part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ensemble to each baseline classifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('cart', DecisionTreeClassifier()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    # define meta learner model\n",
    "    level1 = lgb.LGBMClassifier()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=2)\n",
    "    return model\n",
    "\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "#     models['lr'] = LogisticRegression()\n",
    "#     models['knn'] = KNeighborsClassifier()\n",
    "#     models['cart'] = DecisionTreeClassifier()\n",
    "#     models['svm'] = SVC()\n",
    "#     models['bayes'] = GaussianNB()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    " \n",
    "\n",
    "def extraFun(train, test):\n",
    "    # define dataset\n",
    "    # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X = train\n",
    "    y = labels\n",
    "    # get the models to evaluate\n",
    "    models = get_models()\n",
    "    # evaluate the models and store results\n",
    "    results, names = list(), list()\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    # plot model performance for comparison\n",
    "    pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraFun(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun2(train, test):\n",
    "    # define dataset\n",
    "    # define dataset\n",
    "    # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X = train\n",
    "    y = labels\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('bayes', BernoulliNB()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=3)\n",
    "    # fit the model on all available data\n",
    "    model.fit(X, y)\n",
    "    # make a prediction for one example\n",
    "    model_pred = model.predict_proba(test)\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun2(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make predictions using gradient boosting for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import re\n",
    "def myBooster(train,test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    # define the model\n",
    "    model = GradientBoostingClassifier()\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='roc_auc_ovo_weighted', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    # fit the model on the whole dataset\n",
    "    model.fit(X, y)\n",
    "    model_pred = model.predict_proba(test)[:,1]\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "ROC 0.7498804049341202\n"
     ]
    }
   ],
   "source": [
    "myBooster(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.SCORERS.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "def myHistBooster(train, test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='roc_auc_ovo_weighted', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    model_pred = model.predict_proba(test)[:,1]\n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik, average=\"micro\")\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print('F1 score: %f' % f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "ROC 0.7550468728086515\n",
      "F1 score: 0.921516\n"
     ]
    }
   ],
   "source": [
    "myHistBooster(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def myHistBooster2(train, test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    grid = dict()\n",
    "    grid['learning_rate'] = [0.01]\n",
    "    \n",
    "    grid['max_depth'] = [3]\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # define the grid search procedure\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='roc_auc_ovo_weighted',error_score='raise')\n",
    "    # execute the grid search\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize the best score and configuration\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    # summarize all scores that were evaluated\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myHistBooster2(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
