{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents:\n",
    "* 1 [Preparation](#intro-bullet)\n",
    "* 2 [Logistic Regression](#first-bullet)\n",
    "* 3 [Random Forest](#second-bullet)\n",
    "* 3 [Balanced Random Forest](#third-bullet)\n",
    "* 4 [Naive Bayes](#fourth-bullet)\n",
    "* 5 [KNN](#fifth-bullet)\n",
    "* 6 [Decision Tree](#sixth-bullet)\n",
    "* 7 [Stacking](#seventh-bullet)\n",
    "* 8 [Boosting](#eigth-bullet)\n",
    "    * 8.1 [LigthGBM](#nineth-bullet)\n",
    "    * 8.2 [Gradient Boosting](#tenth-bullet)\n",
    "    * 8.3 [Histogram Gradient Boosting 1](#eleventh-bullet)\n",
    "    * 8.4 [Histogram Gradient Boosting 2](#12-bullet)\n",
    "* 9 [Bagging](#13-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation <a class=\"anchor\" id=\"intro-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = pd.read_csv(\"./featureData.csv\")\n",
    "# split into train test sets\n",
    "train_data, test_data = train_test_split(tmp_data,test_size=0.2)\n",
    "\n",
    "test_data.reset_index(inplace = True, drop = True)\n",
    "train_data.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data.drop(columns='Unnamed: 0')\n",
    "train_data=train_data.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>...</th>\n",
       "      <th>BureauMin_bureau_STATUS_3_count_mean_norm</th>\n",
       "      <th>BureauMin_bureau_STATUS_4_count_mean_norm</th>\n",
       "      <th>BureauMin_bureau_STATUS_5_count_mean_norm</th>\n",
       "      <th>BureauMin_bureau_STATUS_C_count_mean_norm</th>\n",
       "      <th>BureauMin_bureau_STATUS_X_count_mean_norm</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_CREDIT_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <th>PAYMENT_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185409</td>\n",
       "      <td>0</td>\n",
       "      <td>9514</td>\n",
       "      <td>910.0</td>\n",
       "      <td>6271.0</td>\n",
       "      <td>2197</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.095649</td>\n",
       "      <td>0.162999</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>0.176339</td>\n",
       "      <td>0.028743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205983</td>\n",
       "      <td>0</td>\n",
       "      <td>19143</td>\n",
       "      <td>5101.0</td>\n",
       "      <td>2711.0</td>\n",
       "      <td>2621</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.266468</td>\n",
       "      <td>0.450751</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.158852</td>\n",
       "      <td>0.071603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430183</td>\n",
       "      <td>0</td>\n",
       "      <td>15222</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>6928.0</td>\n",
       "      <td>4675</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.140455</td>\n",
       "      <td>0.134072</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.205583</td>\n",
       "      <td>0.027563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200740</td>\n",
       "      <td>1</td>\n",
       "      <td>14418</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>4711.0</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294599</td>\n",
       "      <td>0.294599</td>\n",
       "      <td>0.294599</td>\n",
       "      <td>0.294599</td>\n",
       "      <td>0.294599</td>\n",
       "      <td>0.154668</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.044240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190706</td>\n",
       "      <td>0</td>\n",
       "      <td>20066</td>\n",
       "      <td>12888.0</td>\n",
       "      <td>13021.0</td>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.642280</td>\n",
       "      <td>0.469043</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.098077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0      185409       0        9514          910.0             6271.0   \n",
       "1      205983       0       19143         5101.0             2711.0   \n",
       "2      430183       0       15222         2138.0             6928.0   \n",
       "3      200740       1       14418         2230.0             4711.0   \n",
       "4      190706       0       20066        12888.0            13021.0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  FLAG_EMP_PHONE  REGION_RATING_CLIENT  \\\n",
       "0             2197               1                     2   \n",
       "1             2621               1                     3   \n",
       "2             4675               1                     2   \n",
       "3              286               1                     2   \n",
       "4             3134               1                     2   \n",
       "\n",
       "   REGION_RATING_CLIENT_W_CITY  REG_CITY_NOT_LIVE_CITY  ...  \\\n",
       "0                            2                       1  ...   \n",
       "1                            3                       0  ...   \n",
       "2                            2                       0  ...   \n",
       "3                            2                       0  ...   \n",
       "4                            2                       0  ...   \n",
       "\n",
       "   BureauMin_bureau_STATUS_3_count_mean_norm  \\\n",
       "0                                   0.304721   \n",
       "1                                   0.304721   \n",
       "2                                   0.304721   \n",
       "3                                   0.294599   \n",
       "4                                   0.123264   \n",
       "\n",
       "   BureauMin_bureau_STATUS_4_count_mean_norm  \\\n",
       "0                                   0.304721   \n",
       "1                                   0.304721   \n",
       "2                                   0.304721   \n",
       "3                                   0.294599   \n",
       "4                                   0.123264   \n",
       "\n",
       "   BureauMin_bureau_STATUS_5_count_mean_norm  \\\n",
       "0                                   0.304721   \n",
       "1                                   0.304721   \n",
       "2                                   0.304721   \n",
       "3                                   0.294599   \n",
       "4                                   0.123264   \n",
       "\n",
       "   BureauMin_bureau_STATUS_C_count_mean_norm  \\\n",
       "0                                   0.304721   \n",
       "1                                   0.304721   \n",
       "2                                   0.304721   \n",
       "3                                   0.294599   \n",
       "4                                   0.123264   \n",
       "\n",
       "   BureauMin_bureau_STATUS_X_count_mean_norm  DAYS_EMPLOYED_PERC  \\\n",
       "0                                   0.304721            0.095649   \n",
       "1                                   0.304721            0.266468   \n",
       "2                                   0.304721            0.140455   \n",
       "3                                   0.294599            0.154668   \n",
       "4                                   0.123264            0.642280   \n",
       "\n",
       "   INCOME_CREDIT_PERC  INCOME_PER_PERSON  ANNUITY_INCOME_PERC  PAYMENT_RATE  \n",
       "0            0.162999           252000.0             0.176339      0.028743  \n",
       "1            0.450751           121500.0             0.158852      0.071603  \n",
       "2            0.134072            90000.0             0.205583      0.027563  \n",
       "3            0.200000           135000.0             0.221200      0.044240  \n",
       "4            0.469043            45000.0             0.209100      0.098077  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "def LogRegModel(train, test):\n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET'])\n",
    "    test= test.drop(columns = ['TARGET'])\n",
    "    # Make the model with the specified regularization parameter\n",
    "    log_reg = LogisticRegression(C = 0.0001)\n",
    "    # Train on the training data\n",
    "    log_reg.fit(train, labels)\n",
    "    # Select only second column(TARGET)\n",
    "    log_reg_pred = log_reg.predict_proba(test)[:, 1]\n",
    "    tescik = log_reg.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, log_reg_pred))\n",
    "    print('F1 score: %f' % f1)\n",
    "    return roc_auc_score(test_labels, log_reg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split results:\n",
      "ROC 0.6324377697976515\n",
      "F1 score: 0.000000\n"
     ]
    }
   ],
   "source": [
    "LogRegScore = LogRegModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def RanForModel(train,test):\n",
    "    rf = RandomForestClassifier(n_estimators=100,\n",
    "                                max_depth=10,min_samples_split=20,\n",
    "                                min_samples_leaf=6,\n",
    "                                max_features='auto')\n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET'])\n",
    "    test= test.drop(columns = ['TARGET'])\n",
    "    \n",
    "    rf.fit(X = train, y = labels)\n",
    "    # Select only second column(TARGET)\n",
    "    ran_for_pred = rf.predict_proba(test)[:, 1]\n",
    "    \n",
    "    tescik = rf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('F1 score: %f' % f1)\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, ran_for_pred))\n",
    "    return roc_auc_score(test_labels, ran_for_pred)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandForScore = RanForModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Balanced Random Forest <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "def imbalancedRanFor(train,test):\n",
    "    rf = BalancedRandomForestClassifier()\n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET'])\n",
    "    test= test.drop(columns = ['TARGET'])\n",
    "    \n",
    "    rf.fit(X = train, y = labels)\n",
    "    # Select only second column(TARGET)\n",
    "    ran_for_pred = rf.predict_proba(test)[:, 1]\n",
    "    \n",
    "    tescik = rf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('F1 score: %f' % f1)\n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, ran_for_pred))\n",
    "    return roc_auc_score(test_labels, ran_for_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbRanFor =imbalancedRanFor(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayesian<a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def NaiveBayModel(train,test):\n",
    "    \n",
    "    \n",
    "    clf = BernoulliNB()\n",
    "    \n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    clf.fit(X = train, y = labels)\n",
    "    clf_pred = clf.predict_proba(test)[:, 1]\n",
    "    tescik = clf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, clf_pred))\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    print('F1 score: %f' % f1)\n",
    "    return roc_auc_score(test_labels, clf_pred)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveScore = NaiveBayModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. K-Nearest Neighbors <a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def KNNModel(train,test):\n",
    "    \n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    \n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    clf.fit(X = train, y = labels)\n",
    "    clf_pred = clf.predict_proba(test)[:, 1]\n",
    "    tescik = clf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, clf_pred))\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    print('F1 score: %f' % f1)\n",
    "    return roc_auc_score(test_labels, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnModel = KNNModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision Three <a class=\"anchor\" id=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DTModel(train,test):\n",
    "    \n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    \n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    clf.fit(X = train, y = labels)\n",
    "    clf_pred = clf.predict_proba(test)[:, 1]\n",
    "    tescik = clf.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, clf_pred))\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    print('F1 score: %f' % f1)\n",
    "    return roc_auc_score(test_labels, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTmodel = DTModel(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stacking <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "def fun2(train, test):\n",
    "    # define dataset\n",
    "  \n",
    "    # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X = train\n",
    "    y = labels\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('bayes', BernoulliNB()))\n",
    "    level0.append(('rf',RandomForestClassifier(n_estimators=100,\n",
    "                                max_depth=10,min_samples_split=20,\n",
    "                                min_samples_leaf=6,\n",
    "                                max_features='auto')))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression(C = 0.0001)\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=2)\n",
    "    # fit the model on all available data\n",
    "    model.fit(X, y)\n",
    "    # make a prediction for one example\n",
    "    model_pred = model.predict_proba(test)[:,1]\n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print(\"F1 score \", f1)\n",
    "    return roc_auc_score(test_labels, model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackingScore = fun2(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Boosting <a class=\"anchor\" id=\"eigth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 LightGBM <a class=\"anchor\" id=\"nineth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def PlainLightGBM(train,test):\n",
    "    \n",
    "     # Extract the ids\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "   \n",
    "    model = lgb.LGBMClassifier()\n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "    n_scores = cross_val_score(model, train, labels, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    model.fit(train, labels)\n",
    "    model_pred = model.predict_proba(test)[:, 1]\n",
    "   \n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "     \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print('F1 score: %f' % f1)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    return roc_auc_score(test_labels, model_pred)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plainLGBMScore=PlainLightGBM(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Gradient Boosting  <a class=\"anchor\" id=\"tenth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# make predictions using gradient boosting for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import re\n",
    "\n",
    "def myBooster(train,test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    # define the model\n",
    "    model = GradientBoostingClassifier()\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='roc_auc_ovo_weighted', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    model.fit(X, y)\n",
    "    # make a prediction for one example\n",
    "    model_pred = model.predict_proba(test)[:,1]\n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print('F1 score: %f' % f1)\n",
    "    return roc_auc_score(test_labels, model_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Histogram Gradient Boosting  <a class=\"anchor\" id=\"11th-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "def myHistBooster(train, test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    model_pred = model.predict_proba(test)[:,1]\n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print('F1 score: %f' % f1)\n",
    "    return roc_auc_score(test_labels, model_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hist1BoosterScore = myHistBooster(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import re \n",
    "def myHistBooster2(train, test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    grid = dict()\n",
    "    grid['learning_rate'] = [0.01, 0.001, 0.1]\n",
    "    \n",
    "    grid['max_depth'] = [3, 5 ,7 ]\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # define the grid search procedure\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='roc_auc',error_score='raise')\n",
    "    # execute the grid search\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize the best score and configuration\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    # summarize all scores that were evaluated\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hist2BoosterScore = myHistBooster2(train_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Bagging <a class=\"anchor\" id=\"12th-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "def bagging(train, test):\n",
    "    train_ids = train['SK_ID_CURR']\n",
    "    test_ids = test['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train['TARGET']\n",
    "    test_labels = test['TARGET']\n",
    "    # Remove the ids and target\n",
    "    train = train.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    test= test.drop(columns = ['TARGET','SK_ID_CURR'])\n",
    "    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    \n",
    "    # define dataset\n",
    "    X = train\n",
    "    y = labels\n",
    "    seed = 1\n",
    "   \n",
    "    # initialize the base classifier \n",
    "    base_cls = RandomForestClassifier(n_estimators = 100, n_jobs = -1)\n",
    "     \n",
    "  \n",
    "    # no. of base classifier \n",
    "    num_trees = 100\n",
    "  \n",
    "    # bagging classifier \n",
    "    model = BaggingClassifier(base_estimator = base_cls, \n",
    "                          random_state = seed,\n",
    "                             n_jobs=-1) \n",
    "    print(\"hello\")\n",
    "    model.fit(X,y)\n",
    "    model_pred = model.predict_proba(test)[:,1]\n",
    "    tescik = model.predict(test)\n",
    "    f1 = f1_score(test_labels, tescik)\n",
    "    cm = confusion_matrix(test_labels, tescik)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train/Test split results:')\n",
    "    print(\"ROC\",  roc_auc_score(test_labels, model_pred))\n",
    "    print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BagginScore=bagging(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
